{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f08b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import time\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# ===============================\n",
    "# FUNKCJE AKTYWACJI\n",
    "# ===============================\n",
    "def relu(x, derivative=False):\n",
    "    if derivative:\n",
    "        return (x > 0).astype(float)\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "# ===============================\n",
    "# INICJALIZACJA WAG + BIASÓW\n",
    "# ===============================\n",
    "def initialize_parameters(layer_sizes):\n",
    "    weights, biases = [], []\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        W = np.random.randn(layer_sizes[i], layer_sizes[i + 1]) * np.sqrt(2 / layer_sizes[i])\n",
    "        b = np.zeros((1, layer_sizes[i + 1]))\n",
    "        weights.append(W)\n",
    "        biases.append(b)\n",
    "    return weights, biases\n",
    "\n",
    "# ===============================\n",
    "# FORWARD / BACKWARD\n",
    "# ===============================\n",
    "def forward(X, weights, biases):\n",
    "    activations = [X]\n",
    "    for W, b in zip(weights[:-1], biases[:-1]):\n",
    "        A = relu(activations[-1] @ W + b)\n",
    "        activations.append(A)\n",
    "    A_out = softmax(activations[-1] @ weights[-1] + biases[-1])\n",
    "    activations.append(A_out)\n",
    "    return activations\n",
    "\n",
    "def backward(activations, weights, y):\n",
    "    deltas = [activations[-1] - y]\n",
    "    for i in reversed(range(len(weights) - 1)):\n",
    "        delta = deltas[0] @ weights[i + 1].T\n",
    "        delta *= relu(activations[i + 1], derivative=True)\n",
    "        deltas.insert(0, delta)\n",
    "\n",
    "    grads_W, grads_b = [], []\n",
    "    for i in range(len(weights)):\n",
    "        grads_W.append(activations[i].T @ deltas[i] / len(y))\n",
    "        grads_b.append(np.mean(deltas[i], axis=0, keepdims=True))\n",
    "    return grads_W, grads_b\n",
    "\n",
    "# ===============================\n",
    "# TRENING\n",
    "# ===============================\n",
    "def train(X, y, hidden_layers, lr, epochs,\n",
    "          optimizer=\"sgd\", momentum=0.9, beta1=0.9, beta2=0.999):\n",
    "\n",
    "    layer_sizes = [X.shape[1]] + hidden_layers + [y.shape[1]]\n",
    "    weights, biases = initialize_parameters(layer_sizes)\n",
    "\n",
    "    vW = [np.zeros_like(w) for w in weights]\n",
    "    vb = [np.zeros_like(b) for b in biases]\n",
    "    mW = [np.zeros_like(w) for w in weights]\n",
    "    mb = [np.zeros_like(b) for b in biases]\n",
    "    sW = [np.zeros_like(w) for w in weights]\n",
    "    sb = [np.zeros_like(b) for b in biases]\n",
    "    eps = 1e-8\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        activations = forward(X, weights, biases)\n",
    "        grads_W, grads_b = backward(activations, weights, y)\n",
    "\n",
    "        for i in range(len(weights)):\n",
    "            if optimizer == \"sgd\":\n",
    "                weights[i] -= lr * grads_W[i]\n",
    "                biases[i] -= lr * grads_b[i]\n",
    "\n",
    "            elif optimizer == \"momentum\":\n",
    "                vW[i] = momentum * vW[i] - lr * grads_W[i]\n",
    "                vb[i] = momentum * vb[i] - lr * grads_b[i]\n",
    "                weights[i] += vW[i]\n",
    "                biases[i] += vb[i]\n",
    "\n",
    "            elif optimizer == \"adam\":\n",
    "                t += 1  # zwiększamy licznik iteracji\n",
    "\n",
    "                # aktualizacja momentów\n",
    "                mW[i] = beta1 * mW[i] + (1 - beta1) * grads_W[i]\n",
    "                mb[i] = beta1 * mb[i] + (1 - beta1) * grads_b[i]\n",
    "                sW[i] = beta2 * sW[i] + (1 - beta2) * (grads_W[i] ** 2)\n",
    "                sb[i] = beta2 * sb[i] + (1 - beta2) * (grads_b[i] ** 2)\n",
    "\n",
    "                # korekcja biasu\n",
    "                mW_hat = mW[i] / (1 - beta1 ** t)\n",
    "                mb_hat = mb[i] / (1 - beta1 ** t)\n",
    "                sW_hat = sW[i] / (1 - beta2 ** t)\n",
    "                sb_hat = sb[i] / (1 - beta2 ** t)\n",
    "\n",
    "                # update wag i biasów\n",
    "                weights[i] -= lr * mW_hat / (np.sqrt(sW_hat) + eps)\n",
    "                biases[i] -= lr * mb_hat / (np.sqrt(sb_hat) + eps)\n",
    "\n",
    "    return weights, biases\n",
    "\n",
    "# ===============================\n",
    "# PREDYKCJA\n",
    "# ===============================\n",
    "def predict(X, weights, biases):\n",
    "    A = X\n",
    "    for W, b in zip(weights[:-1], biases[:-1]):\n",
    "        A = relu(A @ W + b)\n",
    "    A = softmax(A @ weights[-1] + biases[-1])\n",
    "    return np.argmax(A, axis=1)\n",
    "\n",
    "# ===============================\n",
    "# JEDNA KOMBINACJA\n",
    "# ===============================\n",
    "def run_combination(params):\n",
    "    lr, epochs, hidden, opt, mom, repeat, X_train, y_train_oh, y_train_lbl, X_test, y_test_lbl = params\n",
    "\n",
    "    acc_train, acc_test, prec, rec, f1 = [], [], [], [], []\n",
    "\n",
    "    for _ in range(repeat):\n",
    "        weights, biases = train(\n",
    "            X_train, y_train_oh,\n",
    "            hidden_layers=hidden,\n",
    "            lr=lr,\n",
    "            epochs=epochs,\n",
    "            optimizer=opt,\n",
    "            momentum=mom if mom else 0.0\n",
    "        )\n",
    "\n",
    "        pred_train = predict(X_train, weights, biases)\n",
    "        pred_test = predict(X_test, weights, biases)\n",
    "\n",
    "        acc_train.append(accuracy_score(y_train_lbl, pred_train))\n",
    "        acc_test.append(accuracy_score(y_test_lbl, pred_test))\n",
    "        prec.append(precision_score(y_test_lbl, pred_test, average=\"macro\", zero_division=0))\n",
    "        rec.append(recall_score(y_test_lbl, pred_test, average=\"macro\", zero_division=0))\n",
    "        f1.append(f1_score(y_test_lbl, pred_test, average=\"macro\", zero_division=0))\n",
    "\n",
    "    return {\n",
    "        \"hidden_layers\": str(hidden),\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": epochs,\n",
    "        \"optimizer\": opt,\n",
    "        \"momentum\": mom,\n",
    "        \"acc_train_mean\": np.mean(acc_train),\n",
    "        \"acc_train_best\": np.max(acc_train),\n",
    "        \"acc_test_mean\": np.mean(acc_test),\n",
    "        \"acc_test_best\": np.max(acc_test),\n",
    "        \"precision_mean\": np.mean(prec),\n",
    "        \"recall_mean\": np.mean(rec),\n",
    "        \"f1_mean\": np.mean(f1)\n",
    "    }\n",
    "\n",
    "# ===============================\n",
    "# MAIN\n",
    "# ===============================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # ---- DANE ----\n",
    "    df = pd.read_excel(\"sensor_readings_24_outcome.xlsx\")\n",
    "    X = df[[f\"US{i}\" for i in range(1, 25)]].values\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "    y = df[\"Class\"].values\n",
    "    classes = np.unique(y)\n",
    "    y_idx = np.array([np.where(classes == c)[0][0] for c in y])\n",
    "    y_oh = np.eye(len(classes))[y_idx]\n",
    "\n",
    "    train_mask = df[\"Set\"] == \"train\"\n",
    "    test_mask = df[\"Set\"] == \"test\"\n",
    "\n",
    "    X_train, X_test = X[train_mask], X[test_mask]\n",
    "    y_train_oh = y_oh[train_mask]\n",
    "    y_train_lbl = y_idx[train_mask]\n",
    "    y_test_lbl = y_idx[test_mask]\n",
    "\n",
    "    # ---- HIPERPARAMETRY ----\n",
    "    learning_rates = [0.001, 0.01, 0.05, 0.1]\n",
    "    epochs_list = [1500, 1200, 900, 500]\n",
    "    hidden_layer_configs = [\n",
    "        [128, 64, 32, 16], [64, 32, 16, 8], [32, 16, 8, 4],\n",
    "        [64, 32, 16], [32, 16, 8], [16, 8, 4],\n",
    "        [64, 32], [32, 16], [16, 8], [8, 4],\n",
    "        [64], [32], [16], [8]\n",
    "    ]\n",
    "    optimizers = [\"sgd\", \"momentum\", \"adam\"]\n",
    "    momentum_values = [0.6, 0.7, 0.8, 0.9]\n",
    "    repeat = 4\n",
    "\n",
    "    all_combinations = []\n",
    "    for lr, ep, hid, opt in product(learning_rates, epochs_list, hidden_layer_configs, optimizers):\n",
    "        moms = [None] if opt != \"momentum\" else momentum_values\n",
    "        for m in moms:\n",
    "            all_combinations.append(\n",
    "                (lr, ep, hid, opt, m, repeat,\n",
    "                 X_train, y_train_oh, y_train_lbl,\n",
    "                 X_test, y_test_lbl)\n",
    "            )\n",
    "\n",
    "    total = len(all_combinations)\n",
    "    print(f\"Liczba kombinacji: {total}\")\n",
    "\n",
    "    # ---- PLIK WYNIKÓW ----\n",
    "    output_file = \"porownanie_optymalizatorow_multiproc.xlsx\"\n",
    "    columns = [\n",
    "        \"hidden_layers\", \"learning_rate\", \"epochs\", \"optimizer\", \"momentum\",\n",
    "        \"acc_train_mean\", \"acc_train_best\",\n",
    "        \"acc_test_mean\", \"acc_test_best\",\n",
    "        \"precision_mean\", \"recall_mean\", \"f1_mean\"\n",
    "    ]\n",
    "    pd.DataFrame(columns=columns).to_excel(output_file, index=False)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # ---- MULTIPROCESSING + ZAPIS NA BIEŻĄCO ----\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        for i, res in enumerate(pool.imap_unordered(run_combination, all_combinations), 1):\n",
    "\n",
    "            wb = load_workbook(output_file)\n",
    "            ws = wb.active\n",
    "            ws.append(list(res.values()))\n",
    "            wb.save(output_file)\n",
    "\n",
    "            elapsed = time.time() - start\n",
    "            avg = elapsed / i\n",
    "            remaining = avg * (total - i)\n",
    "\n",
    "            h, rem = divmod(remaining, 3600)\n",
    "            m, s = divmod(rem, 60)\n",
    "\n",
    "            print(\n",
    "                f\"[{i}/{total}] {res['hidden_layers']} | {res['optimizer']} | \"\n",
    "                f\"lr={res['learning_rate']} | ep={res['epochs']} | mom={res['momentum']} | \"\n",
    "                f\"TEST_mean={res['acc_test_mean']:.3f} | \"\n",
    "                f\"ETA {int(h)}h {int(m)}m {int(s)}s\"\n",
    "            )\n",
    "\n",
    "    print(\"\\nZapisano:\", output_file)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
