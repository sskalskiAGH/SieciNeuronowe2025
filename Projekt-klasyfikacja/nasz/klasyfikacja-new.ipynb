{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1156712a",
   "metadata": {},
   "source": [
    "## Klasyfikacja\n",
    "Sieć perceptronowa, wielowarstwowa własna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd31306e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozmiary zbiorów:\n",
      "Train: (30696, 8), Validation: (19562, 8), Test: (19564, 8)\n",
      "\n",
      "Liczebność klas w zbiorze treningowym:\n",
      "{0: 10232, 1: 10232, 2: 10232}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Wczytanie danych\n",
    "data = pd.read_csv('star_classification.csv', delimiter=\",\")\n",
    "\n",
    "# Wybrane cechy\n",
    "features = ['alpha','delta','u','g','r','i','z','redshift']\n",
    "\n",
    "for col in features:\n",
    "    mean = data[col].mean()\n",
    "    std = data[col].std()\n",
    "    data = data[(data[col] >= mean - 3*std) & (data[col] <= mean + 3*std)]\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['class_encoded'] = le.fit_transform(data['class'])  # GALAXY=0, STAR=1, QSO=2\n",
    "\n",
    "# min_count = data['class_encoded'].value_counts().min()\n",
    "# balanced_data = pd.concat([\n",
    "#     df.sample(min_count, random_state=42)\n",
    "#     for _, df in data.groupby('class_encoded')\n",
    "# ])\n",
    "\n",
    "# # Funkcja split_data działa na macierzy numpy, więc tworzymy macierz danych\n",
    "# X = balanced_data[features].values\n",
    "# y_encoded = balanced_data['class_encoded'].values\n",
    "# y = np.eye(3)[y_encoded]  # one-hot\n",
    "\n",
    "# # Łączymy X i y, żeby podział był zsynchronizowany\n",
    "# combined = np.concatenate((X, y), axis=1)\n",
    "\n",
    "X = data[features].values\n",
    "y_encoded = data['class_encoded'].values\n",
    "y = np.eye(3)[y_encoded]\n",
    "combined = np.concatenate((X, y), axis=1)\n",
    "\n",
    "# Podział danych na zbiory treningowe, generalizacyjne i walidacyjne\n",
    "def split_data(data, train_ratio=0.6, validation_ratio=0.2):\n",
    "    np.random.shuffle(data) # tasowanie danych\n",
    "    \n",
    "    train_size = int(len(data) * train_ratio) \n",
    "    validation_size = int(len(data) * validation_ratio)\n",
    "\n",
    "    train_data = data[:train_size] # wybiera obserwacje do liczby \"train_size\"\n",
    "    validation_data = data[train_size:train_size + validation_size] # wybiera obserwacje od \"train_size\" do sumy \"train_size\" i \"validation_size\"\n",
    "    test_data = data[train_size + validation_size:] # wybiera obserwacje od powyzszej sumy do końca\n",
    "\n",
    "    return train_data, validation_data, test_data\n",
    "\n",
    "train_data, validation_data, test_data = split_data(combined)\n",
    "\n",
    "# --- BALANSOWANIE TYLKO ZBIORU TRENINGOWEGO ---\n",
    "train_df = pd.DataFrame(\n",
    "    train_data,\n",
    "    columns=features + ['c0','c1','c2']\n",
    ")\n",
    "train_df['class'] = np.argmax(train_df[['c0','c1','c2']].values, axis=1)\n",
    "\n",
    "min_count = train_df['class'].value_counts().min()\n",
    "\n",
    "balanced_train_df = pd.concat([\n",
    "    df.sample(min_count, random_state=42)\n",
    "    for _, df in train_df.groupby('class')\n",
    "])\n",
    "\n",
    "train_data = balanced_train_df.drop(columns='class').values\n",
    "\n",
    "# Oddzielamy cechy i klasy\n",
    "X_train = train_data[:, :len(features)]\n",
    "y_train = train_data[:, len(features):]\n",
    "X_validation = validation_data[:, :len(features)]\n",
    "y_validation = validation_data[:, len(features):]\n",
    "X_test = test_data[:, :len(features)]\n",
    "y_test = test_data[:, len(features):]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validation = scaler.transform(X_validation)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# --- PODSUMOWANIE ---\n",
    "print(\"Rozmiary zbiorów:\")\n",
    "print(f\"Train: {X_train.shape}, Validation: {X_validation.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# Liczebność klas w train\n",
    "train_classes = np.argmax(y_train, axis=1)\n",
    "unique, counts = np.unique(train_classes, return_counts=True)\n",
    "print(\"\\nLiczebność klas w zbiorze treningowym:\")\n",
    "print(dict(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7dfa95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   hidden_layers optimizer  momentum  learning_rate  learning_rate_adjust  \\\n",
      "0           [10]        gd       0.0           0.01                0.0005   \n",
      "1           [10]        gd       0.9           0.01                0.0005   \n",
      "2           [10]  momentum       0.0           0.01                0.0005   \n",
      "3           [10]  momentum       0.9           0.01                0.0005   \n",
      "4           [10]        gd       0.0           0.01                0.0005   \n",
      "5           [10]        gd       0.9           0.01                0.0005   \n",
      "6           [10]  momentum       0.0           0.01                0.0005   \n",
      "7           [10]  momentum       0.9           0.01                0.0005   \n",
      "8           [10]        gd       0.0           0.01                0.0005   \n",
      "9           [10]        gd       0.9           0.01                0.0005   \n",
      "10          [10]  momentum       0.0           0.01                0.0005   \n",
      "11          [10]  momentum       0.9           0.01                0.0005   \n",
      "12      [10, 10]        gd       0.0           0.01                0.0005   \n",
      "13      [10, 10]        gd       0.9           0.01                0.0005   \n",
      "14      [10, 10]  momentum       0.0           0.01                0.0005   \n",
      "15      [10, 10]  momentum       0.9           0.01                0.0005   \n",
      "16      [10, 10]        gd       0.0           0.01                0.0005   \n",
      "17      [10, 10]        gd       0.9           0.01                0.0005   \n",
      "18      [10, 10]  momentum       0.0           0.01                0.0005   \n",
      "19      [10, 10]  momentum       0.9           0.01                0.0005   \n",
      "20      [10, 10]        gd       0.0           0.01                0.0005   \n",
      "21      [10, 10]        gd       0.9           0.01                0.0005   \n",
      "22      [10, 10]  momentum       0.0           0.01                0.0005   \n",
      "23      [10, 10]  momentum       0.9           0.01                0.0005   \n",
      "\n",
      "    epochs  repeat  accuracy  precision    recall        f1  \n",
      "0     1000       1  0.631670   0.633843  0.706748  0.638198  \n",
      "1     1000       1  0.745400   0.719676  0.759420  0.734117  \n",
      "2     1000       1  0.724647   0.735401  0.794548  0.736768  \n",
      "3     1000       1  0.835821   0.822898  0.868683  0.835865  \n",
      "4     1000       2  0.798201   0.783706  0.830639  0.796655  \n",
      "5     1000       2  0.699192   0.727375  0.764478  0.721015  \n",
      "6     1000       2  0.759507   0.744948  0.797708  0.757620  \n",
      "7     1000       2  0.854222   0.838249  0.881869  0.852129  \n",
      "8     1000       3  0.714629   0.742388  0.795664  0.735054  \n",
      "9     1000       3  0.778624   0.780062  0.828376  0.784683  \n",
      "10    1000       3  0.747649   0.742508  0.788430  0.752075  \n",
      "11    1000       3  0.841546   0.824149  0.871373  0.838730  \n",
      "12    1000       1  0.740544   0.757500  0.825409  0.754547  \n",
      "13    1000       1  0.699346   0.686192  0.740916  0.701256  \n",
      "14    1000       1  0.790483   0.771247  0.786962  0.778052  \n",
      "15    1000       1  0.861889   0.845597  0.888517  0.859405  \n",
      "16    1000       2  0.754907   0.728140  0.781244  0.745766  \n",
      "17    1000       2  0.627377   0.633207  0.681228  0.640930  \n",
      "18    1000       2  0.732826   0.750177  0.799743  0.747178  \n",
      "19    1000       2  0.870221   0.851549  0.895661  0.866802  \n",
      "20    1000       3  0.674249   0.657774  0.734279  0.677246  \n",
      "21    1000       3  0.674913   0.709827  0.747925  0.698872  \n",
      "22    1000       3  0.782458   0.782716  0.833505  0.788912  \n",
      "23    1000       3  0.881977   0.861232  0.905376  0.877713  \n",
      "  hidden_layers optimizer  momentum  learning_rate  learning_rate_adjust  \\\n",
      "0          [10]        gd       0.0           0.01                0.0005   \n",
      "1          [10]        gd       0.9           0.01                0.0005   \n",
      "2          [10]  momentum       0.0           0.01                0.0005   \n",
      "3          [10]  momentum       0.9           0.01                0.0005   \n",
      "4          [10]        gd       0.0           0.01                0.0005   \n",
      "\n",
      "   epochs  repeat  accuracy  precision    recall        f1  \n",
      "0    1000       1  0.631670   0.633843  0.706748  0.638198  \n",
      "1    1000       1  0.745400   0.719676  0.759420  0.734117  \n",
      "2    1000       1  0.724647   0.735401  0.794548  0.736768  \n",
      "3    1000       1  0.835821   0.822898  0.868683  0.835865  \n",
      "4    1000       2  0.798201   0.783706  0.830639  0.796655  \n",
      "  hidden_layers  learning_rate optimizer  momentum  avg_accuracy  \\\n",
      "0      [10, 10]           0.01        gd       0.0      0.723233   \n",
      "1      [10, 10]           0.01        gd       0.9      0.667212   \n",
      "2      [10, 10]           0.01  momentum       0.0      0.768589   \n",
      "3      [10, 10]           0.01  momentum       0.9      0.871362   \n",
      "4          [10]           0.01        gd       0.0      0.714833   \n",
      "5          [10]           0.01        gd       0.9      0.741072   \n",
      "6          [10]           0.01  momentum       0.0      0.743934   \n",
      "7          [10]           0.01  momentum       0.9      0.843863   \n",
      "\n",
      "   avg_precision  avg_recall    avg_f1  best_accuracy   best_f1  \n",
      "0       0.714471    0.780311  0.725853       0.754907  0.754547  \n",
      "1       0.676409    0.723356  0.680353       0.699346  0.701256  \n",
      "2       0.768047    0.806737  0.771381       0.790483  0.788912  \n",
      "3       0.852793    0.896518  0.867974       0.881977  0.877713  \n",
      "4       0.719979    0.777684  0.723302       0.798201  0.796655  \n",
      "5       0.742371    0.784091  0.746605       0.778624  0.784683  \n",
      "6       0.740952    0.793562  0.748821       0.759507  0.757620  \n",
      "7       0.828432    0.873975  0.842242       0.854222  0.852129  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Funkcja aktywacji: Sigmoid\n",
    "def sigmoid(x, derivative=False):\n",
    "    if derivative:\n",
    "        return x * (1 - x)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "def relu(x, derivative=False):\n",
    "    if derivative:\n",
    "        return (x > 0).astype(float)\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Inicjalizacja wag sieci dla wielu warstw ukrytych\n",
    "# def initialize_weights(input_size, hidden_layers_sizes, output_size):\n",
    "#     weights = []\n",
    "#     layer_sizes = [input_size] + hidden_layers_sizes + [output_size]\n",
    "#     for i in range(len(layer_sizes) - 1):\n",
    "#         weights.append(2 * np.random.random((layer_sizes[i], layer_sizes[i+1])) - 1)\n",
    "#     return weights\n",
    "\n",
    "def initialize_weights(input_size, hidden_layers_sizes, output_size):\n",
    "    weights = []\n",
    "    layer_sizes = [input_size] + hidden_layers_sizes + [output_size]\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        weights.append(np.random.randn(layer_sizes[i], layer_sizes[i+1]) * np.sqrt(2 / layer_sizes[i]))\n",
    "    return weights\n",
    "\n",
    "# Podział danych na zbiory treningowe, generalizacyjne i walidacyjne\n",
    "def split_data(data, train_ratio=0.6, validation_ratio=0.2):\n",
    "    np.random.shuffle(data) # tasowanie danych\n",
    "    \n",
    "    train_size = int(len(data) * train_ratio) \n",
    "    validation_size = int(len(data) * validation_ratio)\n",
    "\n",
    "    train_data = data[:train_size] # wybiera obserwacje do liczby \"train_size\"\n",
    "    validation_data = data[train_size:train_size + validation_size] # wybiera obserwacje od \"train_size\" do sumy \"train_size\" i \"validation_size\"\n",
    "    test_data = data[train_size + validation_size:] # wybiera obserwacje od powyzszej sumy do końca\n",
    "\n",
    "    return train_data, validation_data, test_data\n",
    "\n",
    "# Funkcja dostosowująca tempa nauki\n",
    "def adjust_learning_rate(learning_rate, mse, previous_mse, learning_rate_adjust, threshold=0.001):\n",
    "    if mse < previous_mse:\n",
    "        learning_rate *= 1.1  # jeśli błąd maleje, to zwiększa współczynnik uczenia o 10%\n",
    "    else:\n",
    "        learning_rate *= 0.5  # jeśli błąd nie maleje, to zmniejszamy współczynnik uczenia o 50%\n",
    "\n",
    "    if np.abs(mse - previous_mse) < threshold: #jeśli różnica między błędami jest mniejsza niż dany próg to zmniejszamy learning rate, bo zbliżamy się do optymalnej konfiguracji\n",
    "        learning_rate *= learning_rate_adjust\n",
    "\n",
    "    return learning_rate\n",
    "\n",
    "# Trening sieci z wieloma warstwami ukrytymi\n",
    "def train(X, y, learning_rate, learning_rate_adjust, epochs,\n",
    "          hidden_layers_sizes, optimizer, momentum):\n",
    "\n",
    "    input_size = X.shape[1]\n",
    "    output_size = y.shape[1]\n",
    "    weights = initialize_weights(input_size, hidden_layers_sizes, output_size)\n",
    "    velocities = [np.zeros_like(w) for w in weights]\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        activations = [X]\n",
    "        zs = []\n",
    "        for i, w in enumerate(weights):\n",
    "            z = np.dot(activations[-1], w)\n",
    "            if i == len(weights) - 1:\n",
    "                activations.append(softmax(z))\n",
    "            else:\n",
    "                activations.append(relu(z))\n",
    "        predicted_output = activations[-1]\n",
    "\n",
    "        # Backpropagation\n",
    "        error = predicted_output - y  # cross-entropy gradient\n",
    "        deltas = [error] \n",
    "        for i in range(len(weights) - 1, 0, -1):\n",
    "            delta = deltas[-1].dot(weights[i].T) * relu(activations[i], derivative=True)\n",
    "            deltas.append(delta)\n",
    "\n",
    "        deltas.reverse() \n",
    "\n",
    "        # Aktualizacja wag\n",
    "        # for i in range(len(weights)):\n",
    "        #     weights[i] += activations[i].T.dot(deltas[i]) * learning_rate\n",
    "\n",
    "        # # Dostosowanie learning rate\n",
    "        # learning_rate = adjust_learning_rate(\n",
    "        #     learning_rate,\n",
    "        #     np.mean(error ** 2),\n",
    "        #     np.mean((y - predicted_output) ** 2),\n",
    "        #     learning_rate_adjust\n",
    "        # )\n",
    "\n",
    "        # for i in range(len(weights)):\n",
    "        #     weights[i] -= learning_rate * activations[i].T.dot(deltas[i]) / X.shape[0]\n",
    "        for i in range(len(weights)):\n",
    "            grad = activations[i].T.dot(deltas[i]) / X.shape[0]\n",
    "\n",
    "            if optimizer == 'gd':\n",
    "                weights[i] -= learning_rate * grad\n",
    "\n",
    "            elif optimizer == 'momentum':\n",
    "                velocities[i] = momentum * velocities[i] - learning_rate * grad\n",
    "                weights[i] += velocities[i]\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def predict(X, weights):\n",
    "    output = X\n",
    "    for i, w in enumerate(weights):\n",
    "        output = np.dot(output, w)\n",
    "        if i < len(weights) - 1:\n",
    "            output = relu(output)\n",
    "        else:\n",
    "            output = softmax(output)\n",
    "    return output\n",
    "\n",
    "# Funkcja obliczająca błąd predykcji\n",
    "def calculate_error(predictions, labels):\n",
    "    return np.mean(np.abs(predictions - labels))\n",
    "\n",
    "def correct(y, predictions):\n",
    "    # y i predictions są one-hot encoded\n",
    "    y_class = np.argmax(y, axis=1)\n",
    "    pred_class = np.argmax(predictions, axis=1)\n",
    "    correct_predictions = np.sum(y_class == pred_class)\n",
    "    return correct_predictions / len(y)\n",
    "\n",
    "# Parametry sieci\n",
    "learning_rates = [0.01]\n",
    "learning_rate_adjusts = [0.0005]\n",
    "epochses = [1000]\n",
    "repeat = 3\n",
    "optimizers = ['gd', 'momentum']\n",
    "momentums = [0.0, 0.9]\n",
    "# gd → zwykły gradient prosty\n",
    "# momentum → gradient z momentem\n",
    "\n",
    "# Warstwy\n",
    "hidden_layers_sizes_list = [\n",
    "    [10],         \n",
    "    [10, 10]       \n",
    "]\n",
    "\n",
    "# Funkcja obliczająca wyniki dla accuracy, precision, recall, F1\n",
    "def calculate_metrics(y_test_class, y_pred_class):\n",
    "    accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "    precision = precision_score(y_test_class, y_pred_class, average='macro')\n",
    "    recall = recall_score(y_test_class, y_pred_class, average='macro')\n",
    "    f1 = f1_score(y_test_class, y_pred_class, average='macro')\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Przechowywanie wyników dla różnych konfiguracji warstw\n",
    "results = []\n",
    "\n",
    "# Testowanie\n",
    "for hidden_layers_sizes in hidden_layers_sizes_list:  \n",
    "    for r in range(1, repeat + 1):\n",
    "        for lr in learning_rates:\n",
    "            for lr_adj in learning_rate_adjusts:\n",
    "                for epochs in epochses:\n",
    "                    for optimizer in optimizers:\n",
    "                        for momentum in momentums:\n",
    "                            trained_weights = train(\n",
    "                                X_train, y_train, lr, lr_adj, epochs, hidden_layers_sizes, optimizer=optimizer, momentum=momentum\n",
    "                            )\n",
    "                            predictions_train = predict(X_train, trained_weights)\n",
    "                            predictions_validation = predict(X_validation, trained_weights)\n",
    "                            predictions_test = predict(X_test, trained_weights)\n",
    "\n",
    "                            # Zaokrąglamy wyniki do wartości 0 lub 1 dla porównań\n",
    "                            # y_pred = (predictions_test > 0.5).astype(int)\n",
    "                            y_pred_class = np.argmax(predictions_test, axis=1)\n",
    "                            y_test_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "                            # Obliczamy metryki\n",
    "                            accuracy, precision, recall, f1 = calculate_metrics(y_test_class, y_pred_class)\n",
    "\n",
    "                            # Dodanie wyników do tabeli\n",
    "                            results.append({\n",
    "                                'hidden_layers': str(hidden_layers_sizes),\n",
    "                                'optimizer': optimizer,\n",
    "                                'momentum': momentum,\n",
    "                                'learning_rate': lr,\n",
    "                                'learning_rate_adjust': lr_adj,\n",
    "                                'epochs': epochs,\n",
    "                                'repeat': r,\n",
    "                                'accuracy': accuracy,\n",
    "                                'precision': precision,\n",
    "                                'recall': recall,\n",
    "                                'f1': f1\n",
    "                            })\n",
    "\n",
    "# Tworzenie DataFrame z wynikami\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Wyświetlanie wyników\n",
    "print(results_df)\n",
    "print(results_df.head())\n",
    "\n",
    "summary = results_df.groupby(\n",
    "    ['hidden_layers', 'learning_rate', 'optimizer', 'momentum']\n",
    ").agg(\n",
    "    avg_accuracy=('accuracy', 'mean'),\n",
    "    avg_precision=('precision', 'mean'),\n",
    "    avg_recall=('recall', 'mean'),\n",
    "    avg_f1=('f1', 'mean'),\n",
    "    best_accuracy=('accuracy', 'max'),\n",
    "    best_f1=('f1', 'max')\n",
    ").reset_index()\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28666b2c",
   "metadata": {},
   "source": [
    "## Sieć z biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a846c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   hidden_layers optimizer  momentum  learning_rate  learning_rate_adjust  \\\n",
      "0           [10]        gd       0.0           0.01                   0.5   \n",
      "1           [10]        gd       0.9           0.01                   0.5   \n",
      "2           [10]  momentum       0.0           0.01                   0.5   \n",
      "3           [10]  momentum       0.9           0.01                   0.5   \n",
      "4           [10]        gd       0.0           0.01                   0.5   \n",
      "5           [10]        gd       0.9           0.01                   0.5   \n",
      "6           [10]  momentum       0.0           0.01                   0.5   \n",
      "7           [10]  momentum       0.9           0.01                   0.5   \n",
      "8           [10]        gd       0.0           0.01                   0.5   \n",
      "9           [10]        gd       0.9           0.01                   0.5   \n",
      "10          [10]  momentum       0.0           0.01                   0.5   \n",
      "11          [10]  momentum       0.9           0.01                   0.5   \n",
      "12      [10, 10]        gd       0.0           0.01                   0.5   \n",
      "13      [10, 10]        gd       0.9           0.01                   0.5   \n",
      "14      [10, 10]  momentum       0.0           0.01                   0.5   \n",
      "15      [10, 10]  momentum       0.9           0.01                   0.5   \n",
      "16      [10, 10]        gd       0.0           0.01                   0.5   \n",
      "17      [10, 10]        gd       0.9           0.01                   0.5   \n",
      "18      [10, 10]  momentum       0.0           0.01                   0.5   \n",
      "19      [10, 10]  momentum       0.9           0.01                   0.5   \n",
      "20      [10, 10]        gd       0.0           0.01                   0.5   \n",
      "21      [10, 10]        gd       0.9           0.01                   0.5   \n",
      "22      [10, 10]  momentum       0.0           0.01                   0.5   \n",
      "23      [10, 10]  momentum       0.9           0.01                   0.5   \n",
      "\n",
      "    adjusted_lr  epochs  repeat  accuracy  precision    recall  f1_score  \n",
      "0         0.005    1000       1  0.919853   0.892142  0.936922  0.911329  \n",
      "1         0.005    1000       1  0.919853   0.892142  0.936922  0.911329  \n",
      "2         0.005    1000       1  0.919853   0.892142  0.936922  0.911329  \n",
      "3         0.005    1000       1  0.950164   0.930929  0.957321  0.943177  \n",
      "4         0.005    1000       2  0.922306   0.896862  0.937413  0.914150  \n",
      "5         0.005    1000       2  0.922306   0.896862  0.937413  0.914150  \n",
      "6         0.005    1000       2  0.922306   0.896862  0.937413  0.914150  \n",
      "7         0.005    1000       2  0.954457   0.937374  0.959027  0.947554  \n",
      "8         0.005    1000       3  0.918524   0.892533  0.935249  0.910485  \n",
      "9         0.005    1000       3  0.918524   0.892533  0.935249  0.910485  \n",
      "10        0.005    1000       3  0.918524   0.892533  0.935249  0.910485  \n",
      "11        0.005    1000       3  0.952668   0.935038  0.957770  0.945669  \n",
      "12        0.005    1000       1  0.935647   0.910812  0.947031  0.927201  \n",
      "13        0.005    1000       1  0.935647   0.910812  0.947031  0.927201  \n",
      "14        0.005    1000       1  0.935647   0.910812  0.947031  0.927201  \n",
      "15        0.005    1000       1  0.962431   0.947671  0.964540  0.955794  \n",
      "16        0.005    1000       2  0.935545   0.911841  0.946026  0.927254  \n",
      "17        0.005    1000       2  0.935545   0.911841  0.946026  0.927254  \n",
      "18        0.005    1000       2  0.935545   0.911841  0.946026  0.927254  \n",
      "19        0.005    1000       2  0.963147   0.947722  0.966603  0.956774  \n",
      "20        0.005    1000       3  0.937078   0.913223  0.948061  0.928971  \n",
      "21        0.005    1000       3  0.937078   0.913223  0.948061  0.928971  \n",
      "22        0.005    1000       3  0.937078   0.913223  0.948061  0.928971  \n",
      "23        0.005    1000       3  0.963198   0.948735  0.965644  0.956867  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 131\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_results)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# Opcjonalnie zapis\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# df_results.to_csv(\"mlp_results.csv\", index=False)\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mdf_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_layers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptimizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mavg_accuracy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mavg_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mavg_recall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mavg_f1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1_score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_accuracy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_f1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1_score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPodsumowanie wyników:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\groupby\\generic.py:1445\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1442\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[0;32m   1444\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m-> 1445\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1447\u001b[0m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:175\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:406\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;124;03m    Result of aggregation.\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_or_apply_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:1390\u001b[0m, in \u001b[0;36mGroupByApply.agg_or_apply_dict_like\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m   1385\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m: engine, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: engine_kwargs})\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m com\u001b[38;5;241m.\u001b[39mtemp_setattr(\n\u001b[0;32m   1388\u001b[0m     obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1389\u001b[0m ):\n\u001b[1;32m-> 1390\u001b[0m     result_index, result_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_dict_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1393\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:479\u001b[0m, in \u001b[0;36mApply.compute_dict_like\u001b[1;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m         results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m key_data\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[1;32m--> 479\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28mgetattr\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), op_name)(how, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m func\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    482\u001b[0m     ]\n\u001b[0;32m    483\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(func\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keys, results\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:480\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    476\u001b[0m         results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m key_data\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[0;32m    479\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 480\u001b[0m         \u001b[38;5;28mgetattr\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), op_name)(how, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m func\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    482\u001b[0m     ]\n\u001b[0;32m    483\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(func\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keys, results\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\groupby\\generic.py:255\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m    254\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[1;32m--> 255\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_multiple_funcs(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\groupby\\generic.py:360\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[0;32m    359\u001b[0m         key \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mOutputKey(label\u001b[38;5;241m=\u001b[39mname, position\u001b[38;5;241m=\u001b[39midx)\n\u001b[1;32m--> 360\u001b[0m         results[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\groupby\\generic.py:247\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    246\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, func)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, abc\u001b[38;5;241m.\u001b[39mIterable):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;66;03m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\groupby\\groupby.py:2378\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   2371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[0;32m   2372\u001b[0m         grouped_mean,\n\u001b[0;32m   2373\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[0;32m   2374\u001b[0m         engine_kwargs,\n\u001b[0;32m   2375\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2376\u001b[0m     )\n\u001b[0;32m   2377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2380\u001b[0m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\groupby\\groupby.py:1929\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1926\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1929\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1930\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   1931\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\base.py:336\u001b[0m, in \u001b[0;36mSingleDataManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrouped_reduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func):\n\u001b[0;32m    335\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\n\u001b[1;32m--> 336\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[0;32m    339\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_array(res, index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\groupby\\groupby.py:1905\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1903\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marray_func\u001b[39m(values: ArrayLike) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1904\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1905\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[0;32m   1906\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1907\u001b[0m             values,\n\u001b[0;32m   1908\u001b[0m             how,\n\u001b[0;32m   1909\u001b[0m             axis\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1910\u001b[0m             min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   1911\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1912\u001b[0m         )\n\u001b[0;32m   1913\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1914\u001b[0m         \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1915\u001b[0m         \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1916\u001b[0m         \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[0;32m   1917\u001b[0m         \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[0;32m   1918\u001b[0m         \u001b[38;5;66;03m# TODO: avoid special casing SparseArray here\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, SparseArray):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\groupby\\ops.py:812\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[1;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03mReturns the values of a cython operation.\u001b[39;00m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m kind \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 812\u001b[0m cy_op \u001b[38;5;241m=\u001b[39m WrappedCythonOp(kind\u001b[38;5;241m=\u001b[39mkind, how\u001b[38;5;241m=\u001b[39mhow, has_dropped_na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_dropped_na\u001b[49m)\n\u001b[0;32m    814\u001b[0m ids, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_info\n\u001b[0;32m    815\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n",
      "File \u001b[1;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\groupby\\ops.py:726\u001b[0m, in \u001b[0;36mBaseGrouper.has_dropped_na\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhas_dropped_na\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    723\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;124;03m    Whether grouper has null value(s) that are dropped.\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 726\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m((\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_info\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many())\n",
      "File \u001b[1;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\groupby\\ops.py:730\u001b[0m, in \u001b[0;36mBaseGrouper.group_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgroup_info\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m--> 730\u001b[0m     comp_ids, obs_group_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_compressed_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    732\u001b[0m     ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(obs_group_ids)\n\u001b[0;32m    733\u001b[0m     comp_ids \u001b[38;5;241m=\u001b[39m ensure_platform_int(comp_ids)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\groupby\\ops.py:749\u001b[0m, in \u001b[0;36mBaseGrouper._get_compressed_codes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_compressed_codes\u001b[39m(\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    746\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39msignedinteger], npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp]]:\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;66;03m# The first returned ndarray may have any signed integer dtype\u001b[39;00m\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 749\u001b[0m         group_index \u001b[38;5;241m=\u001b[39m get_group_index(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodes\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xnull\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    750\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m compress_group_index(group_index, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort)\n\u001b[0;32m    751\u001b[0m         \u001b[38;5;66;03m# FIXME: compress_group_index's second return value is int64, not intp\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\groupby\\ops.py:675\u001b[0m, in \u001b[0;36mBaseGrouper.codes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39msignedinteger]]:\n\u001b[1;32m--> 675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [ping\u001b[38;5;241m.\u001b[39mcodes \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\groupby\\ops.py:675\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39msignedinteger]]:\n\u001b[1;32m--> 675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodes\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\groupby\\grouper.py:691\u001b[0m, in \u001b[0;36mGrouping.codes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcodes\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39msignedinteger]:\n\u001b[1;32m--> 691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_codes_and_uniques\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\groupby\\grouper.py:801\u001b[0m, in \u001b[0;36mGrouping._codes_and_uniques\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    796\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uniques\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;66;03m# GH35667, replace dropna=False with use_na_sentinel=False\u001b[39;00m\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"Union[\u001b[39;00m\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# ndarray[Any, Any], Index]\", variable has type \"Categorical\")\u001b[39;00m\n\u001b[1;32m--> 801\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[0;32m    802\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouping_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dropna\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[0;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[1;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[0;32m    803\u001b[0m         uniques,\n\u001b[0;32m    804\u001b[0m         codes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    808\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\algorithms.py:595\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    592\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[0;32m    594\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[0;32m    604\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7280\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7194\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# =======================\n",
    "# Parametry symulacji\n",
    "# =======================\n",
    "learning_rates = [0.01]\n",
    "learning_rate_adjusts = [0.5]\n",
    "epochses = [1000]\n",
    "repeat = 3\n",
    "hidden_layers_sizes_list = [[10], [10, 10]]\n",
    "optimizers = ['gd', 'momentum']\n",
    "momentums = [0.0, 0.9]\n",
    "\n",
    "results = []\n",
    "\n",
    "# =======================\n",
    "# Wczytanie danych\n",
    "# =======================\n",
    "data = pd.read_csv('star_classification.csv', delimiter=\",\")\n",
    "\n",
    "features = ['alpha','delta','u','g','r','i','z','redshift']\n",
    "\n",
    "# Usuwanie wartości odstających\n",
    "for col in features:\n",
    "    mean = data[col].mean()\n",
    "    std = data[col].std()\n",
    "    data = data[(data[col] >= mean - 3*std) & (data[col] <= mean + 3*std)]\n",
    "\n",
    "# Kodowanie klas\n",
    "le = LabelEncoder()\n",
    "data['class_encoded'] = le.fit_transform(data['class'])  # GALAXY=0, STAR=1, QSO=2\n",
    "\n",
    "# Dane i etykiety\n",
    "X = data[features].values\n",
    "y = data['class_encoded'].values\n",
    "\n",
    "# Łączymy X i y, żeby podział był zsynchronizowany\n",
    "combined = np.concatenate((X, y.reshape(-1,1)), axis=1)\n",
    "\n",
    "# def split_data(data, train_ratio=0.6, validation_ratio=0.2):\n",
    "#     np.random.shuffle(data)\n",
    "#     train_size = int(len(data) * train_ratio)\n",
    "#     validation_size = int(len(data) * validation_ratio)\n",
    "#     train_data = data[:train_size]\n",
    "#     validation_data = data[train_size:train_size + validation_size]\n",
    "#     test_data = data[train_size + validation_size:]\n",
    "#     return train_data, validation_data, test_data\n",
    "\n",
    "train_data, validation_data, test_data = split_data(combined)\n",
    "\n",
    "train_df = pd.DataFrame(train_data, columns=features + ['class'])\n",
    "min_count = train_df['class'].value_counts().min()\n",
    "balanced_train_df = pd.concat([\n",
    "    df.sample(min_count, random_state=42)\n",
    "    for _, df in train_df.groupby('class')\n",
    "])\n",
    "train_data = balanced_train_df.values\n",
    "\n",
    "X_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1].astype(int)\n",
    "X_validation = validation_data[:, :-1]\n",
    "y_validation = validation_data[:, -1].astype(int)\n",
    "X_test = test_data[:, :-1]\n",
    "y_test = test_data[:, -1].astype(int)\n",
    "\n",
    "# Skalowanie\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validation = scaler.transform(X_validation)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for lr_adj in learning_rate_adjusts:\n",
    "        adjusted_lr = lr * lr_adj\n",
    "        for epochs in epochses:\n",
    "            for hidden_layers in hidden_layers_sizes_list:\n",
    "                for r in range(repeat):\n",
    "                    for optimizer in optimizers:\n",
    "                        for momentum in momentums:\n",
    "                            # Dobór parametrów dla MLPClassifier\n",
    "                            if optimizer == 'gd':\n",
    "                                clf_momentum = 0.0\n",
    "                            else:  # 'momentum'\n",
    "                                clf_momentum = momentum\n",
    "                            \n",
    "                            mlp = MLPClassifier(\n",
    "                                hidden_layer_sizes=hidden_layers,\n",
    "                                activation='logistic',\n",
    "                                max_iter=epochs,\n",
    "                                solver='sgd',\n",
    "                                learning_rate_init=adjusted_lr,\n",
    "                                momentum=clf_momentum,\n",
    "                                random_state=r\n",
    "                            )\n",
    "                            mlp.fit(X_train, y_train)\n",
    "                            \n",
    "                            y_pred = mlp.predict(X_test)\n",
    "                            \n",
    "                            accuracy = accuracy_score(y_test, y_pred)\n",
    "                            precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                            recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                            f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "                            \n",
    "                            results.append({\n",
    "                                \"hidden_layers\": str(hidden_layers_sizes),\n",
    "                                \"optimizer\": optimizer,\n",
    "                                \"momentum\": momentum,\n",
    "                                \"learning_rate\": lr,\n",
    "                                \"learning_rate_adjust\": lr_adj,\n",
    "                                \"adjusted_lr\": adjusted_lr,\n",
    "                                \"epochs\": epochs,\n",
    "                                \"repeat\": r+1,\n",
    "                                \"accuracy\": accuracy,\n",
    "                                \"precision\": precision,\n",
    "                                \"recall\": recall,\n",
    "                                \"f1_score\": f1\n",
    "                            })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results)\n",
    "\n",
    "# Opcjonalnie zapis\n",
    "# df_results.to_csv(\"mlp_results.csv\", index=False)\n",
    "\n",
    "summary = df_results.groupby(\n",
    "    ['hidden_layers', 'learning_rate', 'optimizer', 'momentum']\n",
    ").agg(\n",
    "    avg_accuracy=('accuracy', 'mean'),\n",
    "    avg_precision=('precision', 'mean'),\n",
    "    avg_recall=('recall', 'mean'),\n",
    "    avg_f1=('f1_score', 'mean'),\n",
    "    best_accuracy=('accuracy', 'max'),\n",
    "    best_f1=('f1_score', 'max')\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\nPodsumowanie wyników:\")\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
