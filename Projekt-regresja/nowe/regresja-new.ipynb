{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98495354",
   "metadata": {},
   "source": [
    "Sieć perceptronowa - nasz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b07acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozmiary: Train: (3669, 5), Val: (786, 5), Test: (787, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# ---- WCZYTYWANIE I CZYSZCZENIE ----\n",
    "data = pd.read_csv('XAU_1d_data.csv', delimiter=\";\")\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data.sort_values('Date') # Gwarancja chronologii\n",
    "\n",
    "# Feature Engineering\n",
    "data['Target'] = data['Close'].shift(-1)\n",
    "data = data.dropna()\n",
    "\n",
    "features = ['Open', 'High', 'Low', 'Volume', 'Close']\n",
    "X_raw = data[features].values\n",
    "y_raw = data['Target'].values.reshape(-1, 1)\n",
    "\n",
    "# ---- PODZIAŁ CHRONOLOGICZNY (70%, 15%, 15%) ----\n",
    "n = len(X_raw)\n",
    "train_idx = int(n * 0.7)\n",
    "val_idx = int(n * 0.85)\n",
    "\n",
    "X_train_raw, y_train_raw = X_raw[:train_idx], y_raw[:train_idx]\n",
    "X_val_raw, y_val_raw = X_raw[train_idx:val_idx], y_raw[train_idx:val_idx]\n",
    "X_test_raw, y_test_raw = X_raw[val_idx:], y_raw[val_idx:]\n",
    "\n",
    "# ---- SKALOWANIE ----\n",
    "scaler_x = StandardScaler().fit(X_train_raw)\n",
    "scaler_y = StandardScaler().fit(y_train_raw)\n",
    "\n",
    "X_train, y_train = scaler_x.transform(X_train_raw), scaler_y.transform(y_train_raw)\n",
    "X_val, y_val = scaler_x.transform(X_val_raw), scaler_y.transform(y_val_raw)\n",
    "X_test, y_test = scaler_x.transform(X_test_raw), scaler_y.transform(y_test_raw)\n",
    "\n",
    "print(f\"Dane gotowe. Trening: {len(X_train)}, Walidacja: {len(X_val)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e61364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczynam trening MLP (Własna implementacja)...\n"
     ]
    }
   ],
   "source": [
    "class CustomMLPRegression:\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            # Inicjalizacja He dla ReLU\n",
    "            w = np.random.randn(layer_sizes[i], layer_sizes[i+1]) * np.sqrt(2 / layer_sizes[i])\n",
    "            b = np.zeros((1, layer_sizes[i+1]))\n",
    "            self.weights.append(w)\n",
    "            self.biases.append(b)\n",
    "        \n",
    "        # Buffory dla momentum\n",
    "        self.v_w = [np.zeros_like(w) for w in self.weights]\n",
    "        self.v_b = [np.zeros_like(b) for b in self.biases]\n",
    "\n",
    "    def relu(self, x): return np.maximum(0, x)\n",
    "    def relu_deriv(self, x): return (x > 0).astype(float)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.activations = [X]\n",
    "        self.zs = []\n",
    "        curr = X\n",
    "        for i in range(len(self.weights)):\n",
    "            z = np.dot(curr, self.weights[i]) + self.biases[i]\n",
    "            self.zs.append(z)\n",
    "            curr = self.relu(z) if i < len(self.weights) - 1 else z # Ostatnia warstwa liniowa dla regresji\n",
    "            self.activations.append(curr)\n",
    "        return self.activations[-1]\n",
    "\n",
    "    def backward(self, y_true, lr, momentum):\n",
    "        error = self.activations[-1] - y_true\n",
    "        deltas = [error]\n",
    "        \n",
    "        # Propagacja błędu wstecz\n",
    "        for i in range(len(self.weights) - 1, 0, -1):\n",
    "            delta = np.dot(deltas[-1], self.weights[i].T) * self.relu_deriv(self.zs[i-1])\n",
    "            deltas.append(delta)\n",
    "        deltas.reverse()\n",
    "\n",
    "        # Aktualizacja wag z Momentum\n",
    "        for i in range(len(self.weights)):\n",
    "            grad_w = np.dot(self.activations[i].T, deltas[i]) / y_true.shape[0]\n",
    "            grad_b = np.mean(deltas[i], axis=0, keepdims=True)\n",
    "            \n",
    "            self.v_w[i] = momentum * self.v_w[i] - lr * grad_w\n",
    "            self.v_b[i] = momentum * self.v_b[i] - lr * grad_b\n",
    "            \n",
    "            self.weights[i] += self.v_w[i]\n",
    "            self.biases[i] += self.v_b[i]\n",
    "\n",
    "    def train(self, X, y, epochs, lr, momentum):\n",
    "        for _ in range(epochs):\n",
    "            self.forward(X)\n",
    "            self.backward(y, lr, momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5383796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pliki Excel zostały wygenerowane pomyślnie!\n"
     ]
    }
   ],
   "source": [
    "def get_metrics(model, X, y_scaled, scaler_y):\n",
    "    pred_scaled = model.forward(X)\n",
    "    p = scaler_y.inverse_transform(pred_scaled)\n",
    "    t = scaler_y.inverse_transform(y_scaled)\n",
    "    return mean_squared_error(t, p), mean_absolute_error(t, p), r2_score(t, p)\n",
    "\n",
    "results_mlp = []\n",
    "# Definicja 4 wartości dla każdego kluczowego parametru\n",
    "params_to_test = {\n",
    "    'lr': [0.001, 0.01, 0.05, 0.1],\n",
    "    'epochs': [500, 1000, 1500, 2000],\n",
    "    'layers': [[16], [16, 16], [32, 16], [32, 16, 8]], # liczba warstw/neuronów\n",
    "    'momentum': [0.0, 0.5, 0.9, 0.95]\n",
    "}\n",
    "\n",
    "print(\"Rozpoczynam badanie parametrów własnego MLP...\")\n",
    "\n",
    "# Przykładowa pętla badania wpływu Learning Rate (LR)\n",
    "for lr in params_to_test['lr']:\n",
    "    for r in range(5): # 5 powtórzeń\n",
    "        model = CustomMLPRegression([X_train.shape[1], 16, 1]) # bazowa architektura\n",
    "        model.train(X_train, y_train, epochs=1000, lr=lr, momentum=0.9)\n",
    "        mse, mae, r2 = get_metrics(model, X_test, y_test, scaler_y)\n",
    "        results_mlp.append({'param': 'lr', 'val': lr, 'run': r, 'mse': mse, 'r2': r2})\n",
    "\n",
    "# UWAGA: Analogiczne pętle należy powtórzyć dla reszty słownika params_to_test\n",
    "# (Dla czytelności wklejam schemat badania LR, w sprawozdaniu powtórz dla reszty)\n",
    "\n",
    "df_mlp = pd.DataFrame(results_mlp)\n",
    "df_mlp.to_excel('analiza_mlp_regresja.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93587b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, time_steps=7):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:(i + time_steps)])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "TIME_STEPS = 7\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train, TIME_STEPS)\n",
    "X_val_seq, y_val_seq = create_sequences(X_val, y_val, TIME_STEPS)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test, TIME_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0382be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 10:52:16.175107: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-07 10:52:16.193389: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-07 10:52:16.805500: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-07 10:52:18.652162: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-07 10:52:18.655526: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "/home/sebastian/Studia/.venv/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767779539.477254     906 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1767779539.496790     906 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start eksperymentów dla LSTM ---\n",
      "Testuję learning_rate = 0.0001... Done.\n",
      "Testuję learning_rate = 0.001... Done.\n",
      "Testuję learning_rate = 0.01... Done.\n",
      "Testuję learning_rate = 0.05... Done.\n",
      "Testuję epochs = 20... Done.\n",
      "Testuję epochs = 50... Done.\n",
      "Testuję epochs = 100... Done.\n",
      "Testuję epochs = 150... Done.\n",
      "Testuję units_filters = 16... Done.\n",
      "Testuję units_filters = 32... Done.\n",
      "Testuję units_filters = 64... Done.\n",
      "Testuję units_filters = 128... Done.\n",
      "Testuję batch_size = 16... Done.\n",
      "Testuję batch_size = 32... Done.\n",
      "Testuję batch_size = 64... Done.\n",
      "Testuję batch_size = 128... Done.\n",
      "--- Start eksperymentów dla CNN ---\n",
      "Testuję learning_rate = 0.0001... Done.\n",
      "Testuję learning_rate = 0.001... Done.\n",
      "Testuję learning_rate = 0.01... Done.\n",
      "Testuję learning_rate = 0.05... Done.\n",
      "Testuję epochs = 20... Done.\n",
      "Testuję epochs = 50... Done.\n",
      "Testuję epochs = 100... Done.\n",
      "Testuję epochs = 150... Done.\n",
      "Testuję units_filters = 16... Done.\n",
      "Testuję units_filters = 32... Done.\n",
      "Testuję units_filters = 64... Done.\n",
      "Testuję units_filters = 128... Done.\n",
      "Testuję batch_size = 16... Done.\n",
      "Testuję batch_size = 32... Done.\n",
      "Testuję batch_size = 64... Done.\n",
      "Testuję batch_size = 128... Done.\n",
      "\n",
      "Sukces! Plik 'wyniki_regresja_koncowe_v2.xlsx' jest gotowy.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "def run_keras_experiment(model_type='LSTM'):\n",
    "    final_results = []\n",
    "    \n",
    "    # 4 wartości dla parametru \"liczba warstw\"\n",
    "    layer_configs = [1, 2, 3, 4] \n",
    "    \n",
    "    for layers in layer_configs:\n",
    "        print(f\"Testuję {model_type} z liczbą warstw: {layers}\")\n",
    "        for r in range(5):\n",
    "            model = Sequential()\n",
    "            model.add(Input(shape=(TIME_STEPS, X_train.shape[1])))\n",
    "            \n",
    "            # Dodawanie warstw zgodnie z parametrem\n",
    "            for i in range(layers):\n",
    "                if model_type == 'LSTM':\n",
    "                    # return_sequences=True jest wymagane, gdy kolejna warstwa to też LSTM\n",
    "                    model.add(LSTM(32, return_sequences=(i < layers - 1)))\n",
    "                else: # CNN\n",
    "                    model.add(Conv1D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "            \n",
    "            if model_type == 'CNN': model.add(Flatten())\n",
    "            model.add(Dense(1))\n",
    "            \n",
    "            model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "            model.fit(X_train_seq, y_train_seq, epochs=50, batch_size=32, verbose=0)\n",
    "            \n",
    "            # Ewaluacja\n",
    "            pred = model.predict(X_test_seq, verbose=0)\n",
    "            p = scaler_y.inverse_transform(pred)\n",
    "            t = scaler_y.inverse_transform(y_test_seq)\n",
    "            \n",
    "            final_results.append({\n",
    "                'model': model_type,\n",
    "                'param': 'layer_count',\n",
    "                'val': layers,\n",
    "                'run': r,\n",
    "                'mse': mean_squared_error(t, p),\n",
    "                'r2': r2_score(t, p)\n",
    "            })\n",
    "            \n",
    "    return final_results\n",
    "\n",
    "# Uruchomienie\n",
    "results_lstm = run_keras_experiment('LSTM')\n",
    "results_cnn = run_keras_experiment('CNN')\n",
    "\n",
    "# Zapis do Excela (Podstawa do wykresów w sprawozdaniu)\n",
    "pd.concat([pd.DataFrame(results_lstm), pd.DataFrame(results_cnn)]).to_excel('wyniki_zaawansowane.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e0a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
